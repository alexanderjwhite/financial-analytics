{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1186295c",
   "metadata": {},
   "source": [
    "## Web Scraping Tutorial using BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7c76c6",
   "metadata": {},
   "source": [
    "\n",
    "**1. Prerequisites:**\n",
    "Install the required libraries:\n",
    "```bash\n",
    "pip install requests beautifulsoup4\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaa4997",
   "metadata": {},
   "outputs": [],
   "source": [
    "%conda activate llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61299f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18da801e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ab7491",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.sec.gov/edgar/browse/?CIK=1141391&owner=exclude'\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5894f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc43b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = soup.title.string  # Gets the title of the page\n",
    "title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d200b8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = soup.find_all('p')  # Gets all the paragraphs in the page\n",
    "for p in paragraphs:\n",
    "    print(p.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7867cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "div_with_id = soup.find('div', id='entityInformation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6f8fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_div = first_link.find_parent('div')  # Gets the parent div of the anchor tag\n",
    "sibling_divs = parent_div.find_next_siblings('div')  # Gets all sibling divs of the parent div\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c8fe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "div_text = div_with_id.get_text(strip=True)  # Gets the text inside the div, with whitespace stripped\n",
    "print(div_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abfdd70",
   "metadata": {},
   "source": [
    "\n",
    "**3. Tips:**\n",
    "\n",
    "- Always check the website's `robots.txt` before scraping. Some websites prohibit scraping.\n",
    "- Make sure not to hit the website with too many requests in a short period. This might get your IP banned.\n",
    "- Use the developer tools in your browser to inspect the webpage and identify the tags you need to target.\n",
    "- If the website is dynamic (loads content via JavaScript), you might need tools like Selenium or Scrapy with middleware to execute JavaScript and fetch content.\n",
    "\n",
    "Remember, web scraping can raise legal and ethical concerns. Always ensure you have the right to access and scrape the website and respect the website's terms of service.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
